{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  Positive  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...\n",
       "1  Positive  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...\n",
       "2  Positive  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...\n",
       "3  Positive  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...\n",
       "4  Positive  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Musae\\\\Documents\\\\GitHub-REPOs\\\\NLP-Project\\\\data\\\\ar_reviews_100k.tsv', sep='\\t')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Positive    33333\n",
       "Mixed       33333\n",
       "Negative    33333\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['label']!='Mixed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['تعلَّم', 'ستمائة', 'ذاك', 'هي', 'إلى', 'أربعاء', 'أنشأ', 'بهما', 'إذما', 'فإن', 'تاسع', 'ه', 'مكانكنّ', 'فبراير', 'ثلاثون', 'أُفٍّ', 'حين', 'في', 'ثلاثمئة', 'طَق', 'مائة', 'عل', 'رزق', 'ذلكن', 'اثنا', 'تِي', 'عشرين', 'قلما', 'د', 'خامس', 'أخبر', 'أوشك', 'إذا', 'م', 'أفٍّ', 'كأي', 'دون', 'ديسمبر', 'ذينك', 'ذه', 'ؤ', 'جلل', 'كثيرا', 'بخ', 'إنما', 'أنا', 'لكنَّ', 'بغتة', 'لنا', 'إيهٍ', 'هلم', 'ابتدأ', 'جميع', 'له', 'زود', 'مئتان', 'هَاتَيْنِ', 'سبعة', 'طالما', 'يناير', 'أبٌ', 'هذان', 'سين', 'ز', 'يفعلون', 'علًّ', 'ذيت', 'من', 'لكيلا', 'غالبا', 'إياكن', 'ثمَّ', 'ولا', 'ح', 'اللتيا', 'حزيران', 'تانِك', 'حيثما', 'حبذا', 'ألا', 'هَذِي', 'سبعون', 'شتانَ', 'ليس', 'لن', 'يوان', 'إلَيْكَ', 'ضحوة', 'وما', 'عليه', 'نحن', 'سبعمئة', 'تارة', 'ثماني', 'بضع', 'ط', 'أنت', 'رأى', 'فيم', 'كيت', 'به', 'ذات', 'كانون', 'ين', 'ل', 'أنًّ', 'جير', 'إنا', 'بسّ', 'الذين', 'عند', 'هاهنا', 'شيكل', 'ثمانمئة', 'عجبا', 'أوت', 'إياهم', 'كم', 'بكما', 'ثالث', 'ثلاثاء', 'هلا', 'ف', 'ذين', 'أمام', 'ما انفك', 'خاصة', 'ذي', 'خلافا', 'ص', 'سمعا', 'صهْ', 'كلا', 'ءَ', 'عليك', 'هم', 'تسعة', 'لكما', 'أخذ', 'هنالك', 'اثني', 'دال', 'أوه', 'لسنا', 'أكتوبر', 'فو', 'رجع', 'إى', 'ستة', 'عامة', 'راء', 'أربعمئة', 'أعلم', 'عوض', 'لست', 'والذي', 'أمامكَ', 'أنبأ', 'أيّ', 'اربعين', 'كِخ', 'ء', 'آي', 'كان', 'أبريل', 'إليك', 'خمس', 'سبت', 'لولا', 'حمو', 'بيد', 'تسع', 'فرادى', 'إليكن', 'أينما', 'آب', 'صدقا', 'تسعمئة', 'أكثر', 'حار', 'حسب', 'كذلك', 'لعل', 'حاشا', 'ذال', 'بس', 'قبل', 'أى', 'تسعمائة', 'إليكنّ', 'ئ', 'شباط', 'إيانا', 'بها', 'نحو', 'ثمّة', 'أخٌ', 'إذاً', 'وإن', 'أولئك', 'تين', 'وإذا', 'هيّا', 'لهم', 'بكن', 'بعد', 'أنتن', 'أهلا', 'آها', 'تشرين', 'إلّا', 'إذن', 'مع', 'ثمّ', 'إما', 'لك', 'ثمانية', 'ثامن', 'ستمئة', 'حمٌ', 'رويدك', 'طفق', 'منذ', 'بلى', 'مهما', 'هلّا', 'كلاهما', 'ته', 'تلقاء', 'أرى', 'مكانكم', 'كأين', 'فيه', 'إياها', 'نيسان', 'هذا', 'لات', 'هَذانِ', 'هَذِه', 'مذ', 'بئس', 'درى', 'سرا', 'ذان', 'باء', 'هنا', 'ليست', 'خلف', 'لوما', 'أيها', 'زاي', 'شبه', 'سبحان', 'كلتا', 'صباح', 'لهن', 'أي', 'ذا', 'ثاء', 'مازال', 'كن', 'هاكَ', 'حيَّ', 'لعلَّ', 'ليسا', 'اخلولق', 'أمامك', 'أل', 'آهٍ', 'أيا', 'ماي', 'ّأيّان', 'آه', 'أجل', 'مكانَك', 'عَدَسْ', 'أين', 'ما', 'معاذ', 'قام', 'بك', 'اللاتي', 'ذلك', 'درهم', 'خميس', 'لكي', 'ن', 'ذلكما', 'على', 'حادي', 'همزة', 'أطعم', 'رُبَّ', 'أما', 'هيهات', 'أمد', 'بات', 'ض', 'إيه', 'أعطى', 'إمّا', 'ج', 'كأنّ', 'هذين', 'ريث', 'جيم', 'أسكن', 'ريال', 'فيما', 'هيا', 'فمن', 'صاد', 'ش', 'منها', 'أمس', 'خمسمائة', 'كأيّ', 'ظاء', 'دولار', 'ورد', 'أنّى', 'نعم', 'متى', 'قرش', 'كلّما', 'أجمع', 'إذ', 'مارس', 'لعمر', 'ذلكم', 'بخٍ', 'عشر', 'ثم', 'قطّ', 'لما', 'تاء', 'قاطبة', 'اللذان', 'كيفما', 'بعدا', 'فلس', 'بَسْ', 'أو', 'حبيب', 'ساء', 'جوان', 'سنتيم', 'الألاء', 'كى', 'أ', 'كل', 'صهٍ', 'طاق', 'واهاً', 'خال', 'ة', 'إي', 'شتان', 'بما', 'وهو', 'اللواتي', 'ميم', 'فيفري', 'إحدى', 'الألى', 'غادر', 'ومن', 'إنَّ', 'آناء', 'قاف', 'ماذا', 'حتى', 'إليكَ', 'نَّ', 'لستن', 'اللائي', 'بين', 'تلكم', 'أيضا', 'مليم', 'كأنما', 'ثلاث', 'كما', 'سادس', 'آهاً', 'أنتم', 'ث', 'تخذ', 'هذي', 'أفعل به', 'لستما', 'أول', 'هَؤلاء', 'ممن', 'آض', 'لا سيما', 'أف', 'إزاء', 'هاتين', 'أصبح', 'ر', 'لو', 'شَتَّانَ', 'ولكن', 'تلك', 'غين', 'إليكم', 'يونيو', 'ق', 'تجاه', 'أقبل', 'ست', 'شرع', 'يا', 'استحال', 'إياهما', 'هبّ', 'كسا', 'لهما', 'هيت', 'سحقا', 'آهِ', 'شين', 'ظلّ', 'مافتئ', 'آنفا', 'سبعمائة', 'بؤسا', 'تحت', 'ليت', 'هَاتانِ', 'خلا', 'لئن', 'مه', 'مثل', 'أنتما', 'لكن', 'هَاتِه', 'أربعمائة', 'ثلاثين', 'تفعلون', 'صار', 'تسعون', 'تموز', 'ذواتي', 'والذين', 'غ', 'صبر', 'ليستا', 'سوى', 'ذِه', 'سرعان', 'يوليو', 'خمسون', 'هاته', 'التي', 'نا', 'ياء', 'تفعلان', 'أولالك', 'ليسوا', 'ع', 'وجد', 'علق', 'بماذا', 'أضحى', 'ى', 'الذي', 'كأن', 'انقلب', 'قد', 'ثاني', 'ثمانين', 'عين', 'رابع', 'كيف', 'مرّة', 'بي', 'حاء', 'اثنان', 'ي', 'إلا', 'خ', 'لا', 'كأيّن', 'راح', 'دينار', 'بمن', 'كليهما', 'مساء', 'ترك', 'نون', 'مادام', 'ضاد', 'أن', 'هكذا', 'تلكما', 'ها', 'ذِي', 'أقل', 'هَيْهات', 'أيّان', 'تعسا', 'ثمان', 'ثمة', 'أبدا', 'تَيْنِ', 'حاي', 'كلَّا', 'فيها', 'طاء', 'هاك', 'هَاتِي', 'أيلول', 'كذا', 'هما', 'ذواتا', 'زعم', 'ما أفعله', 'ستون', 'ما برح', 'تينك', 'هاتان', 'بَلْهَ', 'نَخْ', 'اربعون', 'سقى', 'حرى', 'حمدا', 'وا', 'بطآن', 'كلما', 'سوف', 'أربعة', 'ظ', 'جنيه', 'غدا', 'سبع', 'فإذا', 'جمعة', 'وَيْ', 'سبتمبر', 'حجا', 'صراحة', 'ثمانون', 'هَذا', 'عاد', 'علم', 'واو', 'عدا', 'أولاء', 'ثمنمئة', 'عشرة', 'ذَيْنِ', 'سابع', 'منه', 'مما', 'ب', 'وإذ', 'بهن', 'حَذارِ', 'أخو', 'صبرا', 'إليكما', 'اللتين', 'طرا', 'غداة', 'حيث', 'يورو', 'عشرون', 'ستين', 'جويلية', 'هاء', 'إياك', 'ثان', 'لسن', 'يمين', 'تِه', 'جعل', 'تحوّل', 'كاد', 'هَجْ', 'ألف', 'مكانكما', 'لكنما', 'اللذين', 'مايو', 'تي', 'أنى', 'خمسة', 'بهم', 'أم', 'تبدّل', 'نفس', 'اتخذ', 'لستم', 'بعض', 'إياكما', 'أفريل', 'هذه', 'وراءَك', 'بكم', 'أحد', 'لدن', 'الآن', 'أغسطس', 'أوّهْ', 'خبَّر', 'ولو', 'أصلا', 'سبعين', 'أربع', 'و', 'حقا', 'ا', 'فاء', 'ذانِ', 'إنه', 'ك', 'ارتدّ', 'يفعلان', 'تسعين', 'أمّا', 'ليرة', 'هللة', 'ذهب', 'انبرى', 'نبَّا', 'لبيك', 'أنتِ', 'هن', 'س', 'لاسيما', 'إياهن', 'نوفمبر', 'عسى', 'كرب', 'لي', 'شمال', 'كاف', 'إياه', 'ثلاثة', 'أمسى', 'لها', 'ظنَّ', 'كليكما', 'غير', 'ذوا', 'ثلاثمائة', 'بل', 'ذ', 'إياكم', 'آمينَ', 'لدى', 'هَذَيْنِ', 'اثنين', 'دواليك', 'كي', 'تفعلين', 'فضلا', 'عيانا', 'هل', 'فوق', 'إن', 'عدَّ', 'دونك', 'ذو', 'هاتي', 'خمسمئة', 'أبو', 'بنا', 'نيف', 'فلان', 'هو', 'آ', 'وهب', 'إياي', 'واحد', 'خاء', 'وُشْكَانَ', 'أيار', 'لام', 'عن', 'حدَث', 'عاشر', 'خمسين', 'فلا', 'لم', 'آذار', 'جانفي', 'اللتان', 'لمّا', 'مئة', 'تانِ', 'ت', 'ألفى', 'عما', 'لكم', 'هناك', 'هؤلاء', 'ذانك']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Musae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = list(set(stopwords.words('arabic')))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import sys\n",
    "import argparse\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_diacritics(text):\n",
    "    arabic_diacritics = re.compile(\"\"\" ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(arabic_diacritics, '', str(text))\n",
    "    return text\n",
    "\n",
    "def remove_emoji(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_diacritics(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([word for word in tokens if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleanedtext'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleanedtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...</td>\n",
       "      <td>ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...</td>\n",
       "      <td>أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...</td>\n",
       "      <td>هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...</td>\n",
       "      <td>خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...</td>\n",
       "      <td>ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "0  Positive  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...   \n",
       "1  Positive  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...   \n",
       "2  Positive  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...   \n",
       "3  Positive  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...   \n",
       "4  Positive  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...   \n",
       "\n",
       "                                         cleanedtext  \n",
       "0  ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...  \n",
       "1  أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...  \n",
       "2  هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...  \n",
       "3  خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...  \n",
       "4  ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    stemmer = nltk.ISRIStemmer()\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    #stemming\n",
    "    word_list = [stemmer.stem(w) for w in  word_list]\n",
    "    return ' '.join(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleanedtextnew']=df['cleanedtext'].apply(process_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleanedtext</th>\n",
       "      <th>cleanedtextnew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...</td>\n",
       "      <td>ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...</td>\n",
       "      <td>متز نوع نظف وقع جهز شاطيء طعم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...</td>\n",
       "      <td>أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...</td>\n",
       "      <td>سبب نجح امر شخص دول عشق ترب نحب امر ومض فكر نص...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...</td>\n",
       "      <td>هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...</td>\n",
       "      <td>هدف وقي نقل صخب شرع قهر الى هدء جبل شيش عرف حق...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...</td>\n",
       "      <td>خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...</td>\n",
       "      <td>خلص بدئ الل مست بهر زي فيل زرق ميقراش احس حمد ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...</td>\n",
       "      <td>ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...</td>\n",
       "      <td>ياس جلر جزء جزأ دبي ندق كامل خدم ريح نفس وجد</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "0  Positive  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...   \n",
       "1  Positive  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...   \n",
       "2  Positive  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...   \n",
       "3  Positive  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...   \n",
       "4  Positive  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...   \n",
       "\n",
       "                                         cleanedtext  \\\n",
       "0  ممتاز نوعا النظافة والموقع والتجهيز والشاطيء ا...   \n",
       "1  أسباب نجاح الإمارات شخص الدولة يعشق ترابها نحب...   \n",
       "2  هادفة وقوية تنقلك صخب شوارع القاهرة الى هدوء ج...   \n",
       "3  خلصنا مبدئيا اللي مستني ابهار زي الفيل الازرق ...   \n",
       "4  ياسات جلوريا جزء يتجزأ دبي فندق متكامل الخدمات...   \n",
       "\n",
       "                                      cleanedtextnew  \n",
       "0                      متز نوع نظف وقع جهز شاطيء طعم  \n",
       "1  سبب نجح امر شخص دول عشق ترب نحب امر ومض فكر نص...  \n",
       "2  هدف وقي نقل صخب شرع قهر الى هدء جبل شيش عرف حق...  \n",
       "3  خلص بدئ الل مست بهر زي فيل زرق ميقراش احس حمد ...  \n",
       "4       ياس جلر جزء جزأ دبي ندق كامل خدم ريح نفس وجد  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46666\n",
      "46666\n",
      "20000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "### split data to train and test \n",
    "from sklearn.model_selection import train_test_split\n",
    "x,y=df['cleanedtext'],df['label']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "vectorizer=TfidfVectorizer() #(analyzer='char_wb',ngram_range=(3,5),min_df=0.01,max_df=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n8 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1208, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py\", line 1022, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'عبقري الزوسكيند'\n\n--------------------------------------------------------------------------------\n32 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1208, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py\", line 1022, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'استطع إكمال الاحداث لآخر الكتاب أخبرتني صديقتي شوم بأنه كتاب فظيع يفوووتك الجن ومثلث برمودا والسحر والشعوذة وحياة الجن سطح الارض ان نشنق توقعته اكثر إثارة وتشويقا تخويفا بكثييييييييييير لكني أجد الأسلوب ركيك رأيي والصور المستخدمة مستفزة فائدة إطلاقا انها تمت للأحداث بصلة والأوصاف والتشبيهات ضعيفة للغاية ولم تتح فرصة لتصور يقوم بوصفه أبد أخبرتني صديقتي شوم بان احدى إيجابيات الكتاب دقته تتبع خيوط القصة وعدم نسيان احدها رغم كثرة مرت انتوا مناقشة الكتاب كانت باردة للغاية رغم تعارض الآراء مجموعتنا القرائية ينال إعجابي شخصيا ربما ان أعدت قراءته لاحقا سأغير رأيي'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Musae\\Documents\\GitHub-REPOs\\NLP-Project\\Codes\\init4.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Musae/Documents/GitHub-REPOs/NLP-Project/Codes/init4.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(model, parameters, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Musae/Documents/GitHub-REPOs/NLP-Project/Codes/init4.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Perform the grid search on the data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Musae/Documents/GitHub-REPOs/NLP-Project/Codes/init4.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Musae/Documents/GitHub-REPOs/NLP-Project/Codes/init4.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Get the best model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Musae/Documents/GitHub-REPOs/NLP-Project/Codes/init4.ipynb#X30sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m best_model \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m!=\u001b[39m n_candidates \u001b[39m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcv.split and cv.get_n_splits returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minconsistent results. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msplits, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_splits, \u001b[39mlen\u001b[39m(out) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[0;32m    877\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n8 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1208, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py\", line 1022, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'عبقري الزوسكيند'\n\n--------------------------------------------------------------------------------\n32 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1208, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 915, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Musae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py\", line 1022, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'استطع إكمال الاحداث لآخر الكتاب أخبرتني صديقتي شوم بأنه كتاب فظيع يفوووتك الجن ومثلث برمودا والسحر والشعوذة وحياة الجن سطح الارض ان نشنق توقعته اكثر إثارة وتشويقا تخويفا بكثييييييييييير لكني أجد الأسلوب ركيك رأيي والصور المستخدمة مستفزة فائدة إطلاقا انها تمت للأحداث بصلة والأوصاف والتشبيهات ضعيفة للغاية ولم تتح فرصة لتصور يقوم بوصفه أبد أخبرتني صديقتي شوم بان احدى إيجابيات الكتاب دقته تتبع خيوط القصة وعدم نسيان احدها رغم كثرة مرت انتوا مناقشة الكتاب كانت باردة للغاية رغم تعارض الآراء مجموعتنا القرائية ينال إعجابي شخصيا ربما ان أعدت قراءته لاحقا سأغير رأيي'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Assuming x_train, x_test, y_train, y_test, x_train_tfidf, and x_test_tfidf are already defined\n",
    "# Define the model and parameters to tune\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "parameters = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Regularization parameter\n",
    "    'penalty': ['l2'],  # As 'sag' and 'saga' only support 'l2'\n",
    "    'solver': ['sag', 'saga']  # Solvers that are efficient for larger datasets\n",
    "}\n",
    "\n",
    "# Setup the grid search that will test every combination of parameters\n",
    "grid_search = GridSearchCV(model, parameters, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform the grid search on the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict with the best model\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy and confusion matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Logistic Regression Best Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Logistic Regression Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "vectorizer=TfidfVectorizer() #(analyzer='char_wb',ngram_range=(3,5),min_df=0.01,max_df=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=SVC(kernel='rbf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe=make_pipeline(vectorizer,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pipe.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "accuracy_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
